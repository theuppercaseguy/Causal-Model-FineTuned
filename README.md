# Fine Tuning of a Causal Model on distilled-GPT2
This project demonstrates fine-tuning the GPT2 model for finance text generation using the `transformers` library.

## Installation

##### Clone the repository:
```
git clone https://github.com/your-username/your-repository.git
cd your-repository
```

##### Create and activate a virtual environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate  # Windows
```
##### Install the required dependencies:
```
pip install transformers
pip install datasets
```

## Usage
use collab to train the model again, it'll only take 15-20 mins for GPU, and change the txt variable value at the end of the code to whatever suits you for testing


